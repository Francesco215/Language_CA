{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "embedding_dim=17\n",
    "embedding_dim_V=21\n",
    "sequence_length=13\n",
    "\n",
    "Q= torch.rand([sequence_length,embedding_dim])\n",
    "K= torch.rand([sequence_length,embedding_dim])\n",
    "V= torch.rand([sequence_length,embedding_dim_V])\n",
    "\n",
    "edge_index=torch.randint(0,sequence_length,(2,sequence_length*4))\n",
    "\n",
    "senders,receivers=edge_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  8,  9, 10,  4,  3,  7, 12])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senders[receivers==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4614, 1.0000, 0.5386, 0.2418, 0.0557, 0.7025],\n",
      "        [0.8225, 1.0000, 0.1775, 0.0960, 0.6821, 0.2219],\n",
      "        [0.6421, 1.0000, 0.3579, 0.3533, 0.3917, 0.2550],\n",
      "        [0.1475, 1.0000, 0.8525, 0.0511, 0.2874, 0.6615]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def normalize_strength(strength,receivers,shape):\n",
    "    \"\"\"\n",
    "    lets say we have a directed graph with N nodes and M edges.\n",
    "    To represent each one i have 3 M-dimentional vectors which are cal `senders`, `receivers`\n",
    "    and `strength`:\n",
    "    The i-th element of the `senders` vector represents a node  that is directed towards the\n",
    "    i-th element of the `receivers` vector. The strength of this connection is represented by\n",
    "    the i-th element of the `strength` vector.\n",
    "\n",
    "    This function normalizes the strength of each connection by dividing it by the sum of the\n",
    "    strengths of all the connections that are directed towards the same node.\n",
    "\n",
    "    Args:\n",
    "        receivers (torch.Tensor): A vector of length M, where M is the number of edges in the\n",
    "        strength (torch.Tensor): strength of each connection, must be a 2-dimentional tensor (h,M) where\n",
    "            head is the number of heads\n",
    "        shape (torch.Tensor): shape of the output tensor, must be a 2-dimentional tensor (h,N) where\n",
    "            head is the number of heads and N is the number of nodes \n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: strenght vector normalized by the sum of the strengths of all the\n",
    "            connections that are directed towards the same node.\n",
    "    \"\"\"\n",
    "    assert strength.dim()==2, \"strength must be a 2-dimentional tensor (h,M) where head is the number of heads\"\n",
    "    assert len(shape)==2, \"shape must be a 2-dimentional tensor (h,N) where head is the number of heads and N is the number of nodes\"\n",
    "\n",
    "    strengths_sum = torch.zeros(shape)\n",
    "    strengths_sum.index_add_(1, receivers, strength)\n",
    "\n",
    "    return strength / strengths_sum[:,receivers]\n",
    "\n",
    "# Example usage\n",
    "sequence_length=3\n",
    "\n",
    "edge_index=torch.randint(0,sequence_length,(2,sequence_length*2))\n",
    "senders,receivers=edge_index\n",
    "strength = torch.rand([4,senders.shape[0]])\n",
    "\n",
    "\n",
    "normalized_strength = normalize_strength(strength, receivers, [4,sequence_length])\n",
    "\n",
    "print(normalized_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_message(K,Q,V,receivers,senders):\n",
    "    #Q: (N, h, dQ)\n",
    "    #K: (N, h, dK)\n",
    "    #V: (N, h, dV)\n",
    "    #receivers: (M,)\n",
    "    #senders: (M,)\n",
    "    assert K.dim()==Q.dim()==V.dim()==3, \"K,Q,V must be 3-dimentional tensors\"\n",
    "    assert K.shape[0]==Q.shape[0]==V.shape[0], \"K,Q,V must have the same first dimension\"\n",
    "    assert K.shape[1]==Q.shape[1]==V.shape[1], \"K,Q,V must have the same second dimension\"\n",
    "    assert K.shape[2]==Q.shape[2], \"K,Q must have the same third dimension\"\n",
    "\n",
    "    assert receivers.dim()==senders.dim()==1, \"receivers and senders must be 1-dimentional tensors\"\n",
    "    assert receivers.shape[0]==senders.shape[0], \"receivers and senders must have the same length\"\n",
    "\n",
    "    N,h,d=K.shape    \n",
    "    att=(Q[receivers]*K[senders]).sum(dim=-1) #TODO: add multi-head attention\n",
    "    #att: (M,h)\n",
    "    att = torch.exp(att)\n",
    "    att = normalize_strength(att, receivers,[N,h])\n",
    "\n",
    "    att = einops.einsum(att,V[senders],' ... , ... c -> ... c')\n",
    "\n",
    "    out=torch.zeros_like(V)\n",
    "\n",
    "    return out.index_add_(-2,receivers,att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vg/h6knjndn79l9ytz887vfbrcm0000gn/T/ipykernel_56152/4153485692.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreceivers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msenders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/vg/h6knjndn79l9ytz887vfbrcm0000gn/T/ipykernel_56152/3140312885.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(K, Q, V, recievers, senders)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0matt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecievers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msenders\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO: add multi-head attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0matt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "phi(K,Q,V,receivers,senders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6250, 1.0000, 0.3750, 1.0000],\n",
       "        [0.5000, 1.0000, 0.5000, 1.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senders = torch.tensor([0, 1, 2, 2])\n",
    "receivers = torch.tensor([1, 2, 1, 0])\n",
    "strength = torch.tensor([[0.5, 0.2, 0.3, 0.7],[0.3, 0.2, 0.3, 0.7]])\n",
    "\n",
    "nodes=torch.zeros([2,3])\n",
    "print(nodes[:,receivers].shape)\n",
    "#nodes[:,receivers]+=strength\n",
    "\n",
    "nodes=nodes.index_add(1,receivers,strength)\n",
    "\n",
    "strength=strength/nodes[:,receivers]\n",
    "strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "x[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7000, 0.3000, 0.2000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senders = torch.tensor([0, 1, 2, 2])\n",
    "receivers = torch.tensor([1, 2, 1, 0])\n",
    "strength = torch.tensor([0.5, 0.2, 0.3, 0.7])\n",
    "\n",
    "nodes=torch.zeros(3)\n",
    "\n",
    "nodes[receivers]+=strength\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
