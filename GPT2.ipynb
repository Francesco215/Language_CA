{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch, math, einops\n",
    "from src import Tokenizer, linear_unidirectional_graph_maker\n",
    "from torch import nn\n",
    "\n",
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer('gpt2')\n",
    "pretrained = transformers.GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.GPT2 import GPT2, GPT2_Encoder, GPT2_LM_Head\n",
    "\n",
    "encoder=GPT2_Encoder()\n",
    "decoder=GPT2_LM_Head()\n",
    "\n",
    "model=GPT2(encoder, decoder, tokenizer,dropout=0)\n",
    "\n",
    "model.load_from_original(pretrained)\n",
    "\n",
    "graph_maker=linear_unidirectional_graph_maker(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(starting_string, number_of_tokens):\n",
    "    inp=starting_string\n",
    "    print(starting_string,end='')\n",
    "    for _ in range(number_of_tokens):\n",
    "        inp=tokenizer(starting_string)\n",
    "        edge_index=graph_maker(len(inp))\n",
    "        out_p=pretrained(inp)[0][-1]\n",
    "        out=model(inp,edge_index)[-1]\n",
    "\n",
    "        assert torch.allclose(out,out_p,1e-3,1e-3)\n",
    "        temperature=1/1\n",
    "        probabilities = Categorical(logits=out/temperature)\n",
    "        sample=probabilities.sample().item()\n",
    "        print(tokenizer.decode(sample),end='')\n",
    "        starting_string=starting_string+tokenizer.decode(sample)\n",
    "\n",
    "    return starting_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legolas and Gimli advanced on the orcs, raising their weapons with a harrowing war cry.   They took the bloody elves by force and took their Déjà Vu to invade.   At the fighting, they were turned against each other, with both orcs and deer fighting each other.   The two clans became friends, throughout their feud.\n",
      "From his point of view, he could"
     ]
    }
   ],
   "source": [
    "text=\"Legolas and Gimli advanced on the orcs, raising their weapons with a harrowing war cry. \"\n",
    "out = generate(text, 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c94cac80b40987d9dfcd7d9664f83c8b2cf119f0030fe115bcc4b81bcd6645dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
